# -*- coding: utf-8 -*-
"""notebookd9f0942b0e

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/notebookd9f0942b0e-3a9f96eb-d5d6-40d7-b8b1-1415de1269ef.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241205/auto/storage/goog4_request%26X-Goog-Date%3D20241205T095712Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D02b30308d42876c9224096f3c4b8f715f01b0e21bc7dec0608e674554bf7f6c6519fed352a01fe72733ba60c6e4a3bfa37539552aa7c6576fd4c91b56f5d2156da122b2f99f63e9373c1d4f8e739bac7c75d59f8205375cee6b5a6df6d7f4d4f752a0959eac6bf1b1e138b1937f0df7f0fba019404c17eba1b6dadf844bd31263fda2a7326695c164759579c97eff62d4e12a01aba565648481ccff825a996681d3c8746421138ca593a7e098115243c6bee5049b40f30741541f5f9567aefd65f9b9ba7cb5a6c9e9fe5c8c807bd47fb416ef59aa18db74312dbd8764985e48fb620140e242ac4c7b2532fcefa248938909f91a242d41fed2acd356860c3199e
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

dm_2024_isa_5810_lab_2_homework_path = kagglehub.competition_download('dm-2024-isa-5810-lab-2-homework')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import pandas as pd
import json
import re

# 加載數據
data_identification = pd.read_csv("/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv")
emotion = pd.read_csv("/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv")

with open("/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json", "r") as f:
    tweets = [json.loads(line)["_source"]["tweet"] for line in f]

tweets_df = pd.DataFrame(tweets)

# 合併數據
data = data_identification.merge(tweets_df, on="tweet_id", how="left")
data = data.merge(emotion, on="tweet_id", how="left")

# 清理文本數據
def clean_text(text):
    text = re.sub(r"<LH>", "", text)
    text = re.sub(r"#[A-Za-z0-9_]+", "", text)  # 去除hashtags
    text = re.sub(r"@[A-Za-z0-9_]+", "", text)  # 去除用戶提及
    text = re.sub(r"https?://\\S+", "", text)   # 去除URL
    text = re.sub(r"[^a-zA-Z ]", "", text)     # 保留字母和空格
    return text.lower().strip()

data["text"] = data["text"].apply(clean_text)

data

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=1000)
X = vectorizer.fit_transform(data[data["identification"] == "train"]["text"])
y = data[data["identification"] == "train"]["emotion"]

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score

# 劃分訓練集和驗證集
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 訓練模型
model = MultinomialNB()
model.fit(X_train, y_train)

# 驗證模型
y_pred = model.predict(X_val)
print("Accuracy:", accuracy_score(y_val, y_pred))
print("\nClassification Report:\n", classification_report(y_val, y_pred))